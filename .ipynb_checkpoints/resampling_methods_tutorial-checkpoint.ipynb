{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Tests\n",
    "Also referred to as randomization, permutation tests are a type of resampling wherein the distribution of the test statistic under the null hypothesis, $H_0$, is obtained by computing the test statistic for all possible permutations of data points and labels. Of course, in practice the distribution is estimated by sampling random permutations for scalability. Why do we need to know the distribution of the test statistic? \n",
    "\n",
    "To answer this question, we must first define the meaning of a p-value. A popular misconception about the p-value is that it is a probability for how likely it is that either $H_0$ or $H_A$ is true; however, it actually describes how likely it is to observe a test statistic _at least_ as extreme as the observed test statistic on a given distribution. When the p-value is very small, we reject $H_0$ and deem the observed data to be *significant*. Typically, $p<0.05$ is considered to be small.\n",
    "\n",
    "\n",
    "As an example, we might want to test whether the data for groups A and B come from the same underlying distribution or not. For each group, the observed means are $\\mu_A$ and $\\mu_B$, respectively. We can define the null hypothesis that the data come from the same distribution as: \n",
    "\n",
    "$$H_0:\\mu_A-\\mu_B=0$$\n",
    "\n",
    "and the alternative hypothesis that the data do not come from thes ame distribution as: \n",
    "\n",
    "$$H_A:\\mu_A-\\mu_B\\neq0$$\n",
    "\n",
    "The test statistic for the observed data can be described as $T_{obs}=\\mu_A-\\mu_B$. However, because we have no idea what the underlying distribution for this test statistic looks like, we have no way of computing the p-value for this observation! We also have no more observations for this data, so how can we estimate the sampling distribution? In the absence of additional observations, we will randomly relabel the observed data points (i.e. membership in group A vs. B), recompute new test statistics $T_i$ for each permutation $i\\in(1,...,n)$ for $n$ permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Efficacy of a new drug treatment\n",
    "Let's say a new drug has been developed to treat disease X and is in clinical trials. We want to determine the efficacy of this drug based on patient survival outcomes. We have the survival times, measured in days after diagnosis, for a group of patients that received the drug and another group of patients that did not receive the drug. Here, we will test the null hypothesis is that the drug treatment does not prolong survival time from the point of diagnoses, or:\n",
    "$$H_0:\\mu_{treated}-\\mu_{untreated}=0$$\n",
    "The alternative hypothesis states that the drug treatment results in a statistically significant difference in the post-diagnosis survival time:\n",
    "$$H_A:\\mu_{treated}-\\mu_{untreated}\\neq0$$\n",
    "\n",
    "We will start by loading the post-diagnosis survival times, in days, for patients in the untreated and treated groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated = np.asarray([int(x) for x in open('./untreated_survival_times.txt').read().split(',')])\n",
    "treated = np.asarray([int(x) for x in open('./treated_survival_times.txt').read().split(',')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients are in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%d patients in untreated group' % untreated.shape[0])\n",
    "print('%d patients in treated group' % treated.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of survival times for each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((untreated, treated))\n",
    "plt.legend(['untreated', 'treated'])\n",
    "plt.xlabel('post-diagnosis survival time (days)')\n",
    "plt.ylabel('number of patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the test statistic $T_{obs}$\n",
    "$$T_{obs} = \\mu_{treated}-\\mu_{untreated}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tObs = treated.mean() - untreated.mean()\n",
    "print('t_Obs = %.3g' % tObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test\n",
    "In order to estimate the distribution of the test statistic $T_{obs}$, we will shuffle the data points and randomly relabel them (treated/untreated) $N$ times ($N$ permutations) and recompute the test statistic $T_i = \\mu_{treated}-\\mu_{untreated}$ for $i\\in\\{1,...,N\\}$. For this example, we will run 1000 permutations ($N=1000$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "testStats = []\n",
    "\n",
    "pooled_data = np.hstack([treated, untreated])\n",
    "sizeTreated = np.shape(treated)[0]\n",
    "sizeUntreated = np.shape(untreated)[0]\n",
    "\n",
    "for i in range(N):\n",
    "    np.random.shuffle(pooled_data)\n",
    "    permTreated = pooled_data[:sizeTreated]\n",
    "    permUntreated = pooled_data[-sizeUntreated:]\n",
    "    ti = permTreated.mean() - permUntreated.mean()\n",
    "    testStats.append(ti)\n",
    "    print('permutation %d: t_i = %.3g' % (i+1, ti))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at that distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(testStats)\n",
    "plt.title('Est. distribution of test statistic (N = %d)' % N)\n",
    "plt.xlabel('T')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute p-value\n",
    "Now that you have generated 1000 estimates of the test statistic with permuted data labels, you can compute the p-value for $T_{obs}$. As a reminder, the p-value is a measure of how likely it is to get a test statistic _at least_ as extreme as what you observed. Thus, $p$ can be computed as:\n",
    "\n",
    "$$ p = \\frac{\\text{# of permutations where } T_i \\geq T_{obs}}{\\text{total # of permutations}} $$\n",
    "\n",
    "Visually, that would look like the probability that you would observe a test statistic that falls to the right of the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(testStats)\n",
    "plt.title('Est. distribution of test statistic (%d permutations)' % N)\n",
    "plt.xlabel('T')\n",
    "plt.axvline(tObs, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sum(testStats>=tObs)/N\n",
    "print('p = %.3g' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "A significance threshold at $\\alpha=0.05$ is popularly used for most statistical analyses. When $p<0.05$, this means that there is a less than 5% chance that you would observe a test statistic at least as extreme as $T_{obs}$ under the null distribution. In this case, how should we interpret the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping\n",
    "\n",
    "Let's say we want to know the true difference in the mean survival post-diagnosis between treated and untreated patients. Given the same data used bove, we can use bootstrapping - or sampling with replacement - to estimate a confidence interval between which this true mean lies.\n",
    "\n",
    "To do this, we will sample from each group with replacement and compute the difference in the means of the resampled groups. Each resampled group should be the same size as the original group. We will repeat this process $N = 1000$ times (as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_differences = []\n",
    "\n",
    "for i in range(N):\n",
    "    sample_untreated = np.random.choice(untreated, size = untreated.shape)\n",
    "    sample_treated = np.random.choice(treated, size = treated.shape)\n",
    "    \n",
    "    bootstrap_diff = np.mean(sample_treated) - np.mean(sample_untreated)\n",
    "    mean_differences.append(bootstrap_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get confidence interval - 95%\n",
    "\n",
    "To do this, we will set the bounds of the CI at the 2.5th percentile and 97.5th percentile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = np.quantile(mean_differences, [0.025, 0.975])\n",
    "print('95%% CI bounds: [%.5f, %.5f]' % (ci[0], ci[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the bounds of the CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_differences, color = 'grey', alpha = 0.6, edgecolor = 'white')\n",
    "plt.axvline(ci[0], color = 'red')\n",
    "plt.axvline(ci[1], color = 'red')\n",
    "plt.axvline(tObs)\n",
    "plt.xlabel('mean difference in survival time (days)')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
